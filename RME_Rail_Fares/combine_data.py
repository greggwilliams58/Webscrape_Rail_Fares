from glob import glob
from datetime import datetime
import sys
import os
import pandas as pd
#import pprint as pp
#import RME_webscrape


def tidyupfiles(dailydatapath, appendeddatapath):
    """
    This serves the purpose of appending daily data to a combined dataset and then deleting the daily data and previous combined dataset

    Parameters:
    dailydatapath:      A string representing the path to the daily data generated by RME_webscrape
    appendeddatapath:   A string representing the path to the appended data generated by the previous execution

    Returns:
    None                But manipulates files through appending data and deleting files 
    """
    dailydataname = 'RME_data_collected_for*'
    appendeddataname = 'appended_data'
    fileextension = '.csv'


    dailydata = get_daily_data(dailydatapath,dailydataname,fileextension)
    appendeddata = get_appended_data(appendeddatapath,appendeddataname,fileextension)
    alldata = combine_daily_and_appended_data(dailydata, appendeddata)
    todaysdate = datetime.now().strftime("%Y_%m_%d")
    
    #export all combined data to appenddata folder
    alldata.to_csv(appendeddatapath + appendeddataname  +"_for_"+ todaysdate + fileextension)
    
    #remove files not longer needed
    cleanup(dailydatapath,appendeddatapath,todaysdate)


def get_daily_data(filepath, filename, fileextension):
    """
    This finds the daily dataset file and loads it into a dataframe, with data conversion.  If there are more than one datasets in the folder, all datasets will be concatinated.
    It can handle csv or xslx formats

    Parameters:
    filepath:       A string containing a filepath 
    filename:       A string containing the filename to be loaded
    fileextension:  A string containing a file extension.  Only csv has been implemented

    Output:
    alldailydata:   A DataFrame holding data frames of the daily dataset(s)
    """
    #this is a list f strings
    listoffiles = glob(f'{filepath+filename+fileextension}')
    
    numberoffiles = len(listoffiles)

    print(f"{numberoffiles} {fileextension} files need to be collated") 
    print(f"reading in {fileextension} files from {filepath}")

    #create empty list to hold temp dataframes read in from CSV
    dataframes = []
    dtypedictionary = {'TOC Criteria':str,'Origin':str,'Origin_Code':str,'Destination':str,'Destination_Code':str,'Date_accessed':str,'Time_searched_against':str,'Departure_Gap':str,
                     'Departure_Date':str,'Arrival_time':str,'Duration':str, 'Changes':int,'Price':float,'Fare_Route_Description':str,'Fare_Provider':str,'TOC_Name':str,
                     'TOC_Provider':str,'Ticket_type':str,'nre_fare_category':str,'Duplicate':bool}

    #loop through each daily dataset, appending to a list
    for count, file in enumerate(listoffiles,1):
        print(f"Loading {os.path.basename(file)} into memory.")
        print(f"That's {count} out of {numberoffiles}, or {str(int((count/numberoffiles)*100))} percent loaded.\n")
        temp = pd.read_csv(file,
                            dtype=dtypedictionary,
                            header=0,
                            encoding='Windows-1252',
                            parse_dates=True
                            )
        dataframes.append(temp)

    #join each dataframe in list to each other here
    alldailydata = pd.concat(dataframes,sort=False)
    
    return alldailydata


def get_appended_data(filepath, filename, fileextension):
    """
    This identifies the latest file from the appended folder and loads that file into a dataframe, and deletes previous general index.

    Parameters:
    filepath:       A string containing the filepath to the appended data folder
    filename:       A string containing the generic name of the appended file
    fileextension:  A string containing the file extension.  Only csv is currently supported

    Returns
    df:             A df containing the appended dataset
    """
    list_of_files = glob(filepath +'*') # * means all if need specific format then *.csv
    latest_file = max(list_of_files, key=os.path.getctime)
    print(latest_file)
   
    dtypedictionary = {'TOC Criteria':str,'Origin':str,'Origin_Code':str,'Destination':str,'Destination_Code':str,'Date_accessed':str,'Time_searched_against':str,'Departure_Gap':str,
                     'Departure_Date':str,'Arrival_time':str,'Duration':str, 'Changes':int,'Price':float,'Fare_Route_Description':str,'Fare_Provider':str,'TOC_Name':str,
                     'TOC_Provider':str,'Ticket_type':str,'nre_fare_category':str,'Duplicate':bool}
    
    df = pd.read_csv(latest_file,
                               dtype=dtypedictionary,
                               header=0,
                               encoding='Windows-1252',
                               parse_dates=True      
                     )

    #remove previous index from previously appended dataset
    del df['general_index']  
    
    return df

def combine_daily_and_appended_data(dailydata, appendeddata):
    """
    This appends the two dataframes of daily and appended data, renaming the new index as 'general index'

    Parameters:
    dailydata:      A dataframe containing the daily dataset(s)
    appendeddata:   A dataframe containing the appended data

    Returns:
    all_data:       A dataframe with all data combined and index renamed
    """

    all_data = pd.concat([appendeddata,dailydata],sort=False,ignore_index=True) 
    all_data.rename_axis('general_index',axis='index',inplace=True)

    print(f"alldata is {type(all_data)}")
    return all_data


def cleanup(dailydatapath, appendeddatapath,todaysdate):
    """
    This removes the unnecessary daily and now-historic appended file from the file system

    Parameters:
    dailydatapath:      A string holding the filepath of the daily datasets
    appendeddatapath:   A string holding the filepath of the appended dataset
    todaysdate:         A string representing today's date in DD_MM_YYYY format

    Returns:
    None, but deletes unnecessary files
    """

    #delete from daily data
    dailyfilelist = glob(dailydatapath+'*.csv')
    
    for f in dailyfilelist:
        os.remove(f)
    
    #delete any appended file without today's date
    appendedfilelist = glob(appendeddatapath + '*.csv')
    for f in appendedfilelist:
        if todaysdate not in f:
            os.remove(f)


